{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import pystan\n",
    "\n",
    "# Load training data and reduce (subsample) if desired\n",
    "\n",
    "# Read thru file to get numeric ids for each player \n",
    "with open('train.csv') as f: lines = f.read().split('\\n')\n",
    "\n",
    "p = 0; playerid = {};\n",
    "for i in range(len(lines)):\n",
    "    csv = lines[i].split(',');\n",
    "    if len(csv) != 10: continue;   # parse error or blank line\n",
    "    player0,player1 = csv[1],csv[4];\n",
    "    if player0 not in playerid: playerid[player0]=p; p+=1;\n",
    "    if player1 not in playerid: playerid[player1]=p; p+=1;\n",
    "\n",
    "nplayers = len(playerid)\n",
    "playername = ['']*nplayers\n",
    "for player in playerid: playername[ playerid[player] ]=player;  # id to name lookup\n",
    "\n",
    "\n",
    "# Sparsifying parameters (discard some training examples):\n",
    "pKeep = 1.0   # fraction of edges to consider (immed. throw out 1-p edges)\n",
    "nEdge = 3     # try to keep nEdge opponents per player (may be more; asymmetric)\n",
    "nKeep = 5     # keep at most nKeep games per opponent pairs (play each other multiple times)\n",
    "\n",
    "nplays, nwins = np.zeros( (nplayers,nplayers) ), np.zeros( (nplayers,nplayers) );\n",
    "for i in range(len(lines)):\n",
    "    csv = lines[i].split(',');\n",
    "    if len(csv) != 10: continue;   # parse error or blank line\n",
    "    a,b = playerid[csv[1]],playerid[csv[4]];\n",
    "    aw,bw = csv[2]=='[winner]',csv[5]=='[winner]';\n",
    "    if (np.random.rand() < pKeep):\n",
    "        if (nplays[a,b] < nKeep) and ( ((nplays[a,:]>0).sum() < nEdge) or ((nplays[:,b]>0).sum() < nEdge) ):\n",
    "            nplays[a,b] += 1; nplays[b,a]+=1; nwins[a,b] += aw; nwins[b,a] += bw;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "999"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nplayers # number of unique players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MC vs Stats\n"
     ]
    }
   ],
   "source": [
    "playerid # map from playername -> playerID\n",
    "playername[0] # list of playernames indexed by their ID\n",
    "print(playername[0], \"vs\", playername[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nplays[0,1] # number of games between player 0 and player 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nwins[0,1] # number of wins between player 0 and player 1\n",
    "np.max(nwins) # maximum number of wins against a single opponent is 5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9354.0"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(nplays)  # number of player vs player combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pystan\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "win = []\n",
    "PA = []\n",
    "PB = []\n",
    "for index, wins in np.ndenumerate(nwins):\n",
    "    if wins == 0: continue\n",
    "    win.append(int(wins))\n",
    "    PA.append(index[0] + 1)           # increment so we can index starting at 1\n",
    "    PB.append(index[1] + 1)           # player 0 is now player 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 2, 4, 4, 2]  # of wins PA had over PB\n",
      "[1, 1, 1, 1, 1, 1]  PA's ID\n",
      "[2, 4, 6, 7, 8, 9]  PB's ID\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3321"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(win[:6], \" # of wins PA had over PB\") \n",
    "print(PA[:6], \" PA's ID\") \n",
    "print(PB[:6], \" PB's ID\")\n",
    "len(win)            # total number of games"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Stan Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "skill_model = \"\"\"\n",
    "data {\n",
    "  int<lower=1> N;             # Total number of players i.e 999\n",
    "  int<lower=1> E;             # number of matchups (3321)\n",
    "  real<lower=0> scale;        # scale value for probability computation\n",
    "  int<lower=1,upper=5> win[E];        # PA wins vs PB\n",
    "  int PA[E];                  # player info between each matchup\n",
    "  int PB[E];                  # \n",
    "}\n",
    "parameters {\n",
    "  vector [N] skill;           # skill values for each player\n",
    "}\n",
    "\n",
    "model{\n",
    "  for (i in 1:N){ skill[i]~normal(0,5); }\n",
    "  for (i in 1:E){\n",
    "    win[i] ~ bernoulli_logit(5, (scale)*(skill[PA[i]]-skill[PB[i]]) );\n",
    "  }   # win probability is a binomial_logit function of skill difference (0-5)\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "try:     # load it if already compiled\n",
    "    sm = pickle.load(open('skill_model.pkl', 'rb'))\n",
    "except:  # ow, compile and save compiled model\n",
    "    sm = pystan.StanModel(model_code = skill_model)\n",
    "    with open('skill_model.pkl', 'wb') as f: pickle.dump(sm, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "skill_data = {\n",
    "    'N': 999,\n",
    "    'E': 3321,\n",
    "    'scale': 0.1,\n",
    "    'win': win,\n",
    "    'PA': PA,\n",
    "    'PB': PB\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can perform MCMC on the model, and extract the samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit = sm.sampling(data=skill_data, iter=1000, chains=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = fit.extract()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we just want the mean estimate for each player's skill level, just take the empirical average over the samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.50332678 0.73230844 1.0644105  0.19198068 0.35219029 2.01000608\n",
      " 0.30597953 1.31795097 0.47922447 1.15018521 2.54122717 2.04680167\n",
      " 1.39876339 1.83875431 1.65901077 0.821774   2.844181   2.28370498\n",
      " 1.64128003 1.61818507 2.27469163 1.67491987 0.52268555 0.35581906\n",
      " 0.38440722 2.78075236 0.73082449 1.55409992 0.2307017  0.82132964\n",
      " 1.83349028 3.68042626 1.29675467 1.01321477 2.96246133 2.89739406\n",
      " 2.43988487 2.57616151 0.35509254 2.58563537 2.59593557 0.60280802\n",
      " 1.057093   0.84421652 2.2630846  2.01180351 0.85262577 0.64213773\n",
      " 1.87766629 1.37849551 2.12831478 1.30689973 2.87902817 2.02879487\n",
      " 2.18434828 1.41864851 1.06855203 1.439259   2.5299713  1.38621129\n",
      " 1.09792547 1.78083963 0.43730163 2.07473279 0.69781062 2.561981\n",
      " 2.69392629 0.28735266 0.22468761 0.36605283 1.99617834 2.15565099\n",
      " 3.62381045 0.84189158 0.31195897 2.64411366 0.78009672 2.58985167\n",
      " 0.68207157 2.61677195 0.3684654  0.25107256 2.21245529 1.3164459\n",
      " 1.42517219 2.35191672 0.47624004 3.79557223 1.36109018 3.73046338\n",
      " 2.49305603 3.80059845 2.42836752 3.7508008  1.90871874 2.60619351\n",
      " 1.3520794  3.67450836 3.68317992 0.62252604 2.03880312 2.88918497\n",
      " 1.28190116 2.22261961 0.76629493 1.94173623 2.40733555 2.21622534\n",
      " 2.12603548 1.38359131 2.52540755 3.12649005 2.23499243 3.24686841\n",
      " 3.65146179 2.62951776 3.33328488 2.54962692 3.75873691 2.52961516\n",
      " 1.56618819 0.92242481 1.78933666 1.90504487 3.15771214 2.22813738\n",
      " 1.73110444 3.76314779 2.15056795 2.90427332 1.72916241 2.93942755\n",
      " 0.46186607 1.36057604 3.78235273 1.67847449 3.10402409 2.28870274\n",
      " 2.20134971 1.92850425 2.33088414 3.84014984 3.22104288 2.41174766\n",
      " 3.63814322 3.72322411 0.79683458 3.69514245 1.69954918 2.59558914\n",
      " 1.65389991 1.22040484 2.14921221 2.82119957 3.648584   2.20263279\n",
      " 2.03498208 1.65565808 1.66275347 2.11197868 2.32763094 1.73754671\n",
      " 2.50077951 2.30594757 2.99563606 3.60765985 3.67022248 2.29196969\n",
      " 2.60781067 2.03903927 1.3711403  1.62839136 3.37172203 3.22585909\n",
      " 3.82223295 2.78173951 2.42572419 2.82702257 2.01701132 1.78570943\n",
      " 1.51938069 3.25141596 2.59989102 2.46196895 2.5827776  2.56449005\n",
      " 3.62285251 3.30376389 2.5284782  3.79396832 2.94381039 1.43417959\n",
      " 2.51553168 3.81604081 3.69113028 3.81542715 2.62680627 1.86891192\n",
      " 2.86300993 3.7779962  2.56480624 1.13608661 2.49590725 0.21254723\n",
      " 0.68897885 1.68129838 1.0988696  0.32206431 1.45850362 3.28865982\n",
      " 2.07309838 1.97428753 1.21331293 0.19345907 2.06828364 2.38206118\n",
      " 1.4544445  0.64521765 3.85928446 1.006695   1.73234279 3.72503076\n",
      " 2.25696154 0.77169149 1.71468392 2.5846949  2.23905554 2.99886438\n",
      " 2.9444193  1.53432088 2.32154618 3.91839696 2.67883544 1.25920065\n",
      " 2.02305783 0.82593874 0.42344199 2.4067896  3.71606633 1.57111737\n",
      " 1.77945204 3.7781514  1.88249601 0.52647066 1.1341686  2.40547556\n",
      " 3.40350423 3.78420937 2.38764308 2.72392231 3.70338244 3.78424901\n",
      " 0.37540613 3.83370697 0.41083509 2.07452969 2.55585601 3.37276022\n",
      " 1.67804771 2.53359168 2.53433962 2.85180343 2.11705335 2.01379448\n",
      " 1.8010571  3.82410705 2.8893065  3.05277883 3.75225533 2.90274232\n",
      " 2.99405303 3.37663122 1.60928576 3.73277046 3.24959541 3.84470464\n",
      " 2.20326789 3.77705229 2.3696134  0.33897004 2.48561691 1.1201273\n",
      " 1.15356218 2.1407233  2.60843267 2.92439032 3.36841684 1.93313721\n",
      " 3.72445725 0.25421506 3.31092885 3.7147352  2.96473561 0.86069309\n",
      " 3.96614803 2.05121606 2.47482009 2.44702389 2.23226854 1.87356408\n",
      " 0.39580647 2.89709961 2.5538116  2.45369715 4.23077532 0.72022108\n",
      " 3.298884   2.4915368  0.93011065 1.80638638 3.66625937 2.92794069\n",
      " 2.17438665 1.00852114 2.97303277 0.83075627 0.27469137 1.1367388\n",
      " 1.82659938 3.1442213  1.52138019 3.74392272 2.31665645 3.70038494\n",
      " 1.58992881 3.63290934 3.33259844 2.34605606 2.90272172 2.64855374\n",
      " 2.53979264 2.22754318 3.64711286 2.48809141 1.59278727 2.76502831\n",
      " 3.29253589 3.21382045 3.59602818 3.67626473 3.7784386  4.01372677\n",
      " 3.72754308 2.38531398 3.74600625 2.22985918 3.32633493 3.3234585\n",
      " 2.62947018 2.64462808 3.27390875 2.48903698 2.9138739  3.18865332\n",
      " 2.5576603  3.79065956 2.60135166 3.71359386 3.63051198 3.30003524\n",
      " 3.12457477 2.69921514 3.40270319 2.51013556 1.29142816 2.28935368\n",
      " 1.87844631 4.03789455 1.79354737 3.72209462 3.75339235 2.50655592\n",
      " 1.80025176 2.0457608  2.24225057 3.28305526 1.67096804 3.76449182\n",
      " 3.03683098 3.64334088 1.73560527 2.12659205 2.88662622 3.74349482\n",
      " 1.30201066 2.36896631 3.28069991 2.6077881  2.5915964  3.70145037\n",
      " 3.30125595 3.72222389 2.24401185 1.96110316 1.10169764 2.34517212\n",
      " 2.08834585 3.32900387 1.61395246 3.6918412  2.24600654 3.31259991\n",
      " 2.47089792 3.65179381 3.71170803 1.42674437 2.82421817 2.83968001\n",
      " 4.18259841 3.67868336 2.96697032 2.07609368 2.25263848 3.22689999\n",
      " 3.64466766 3.68743683 1.80588512 2.21508589 3.50755615 3.70633917\n",
      " 3.92070388 1.78305865 3.85390374 2.3049129  3.27167415 3.56704903\n",
      " 2.27833727 1.08344039 2.21442255 1.86354637 1.83197161 1.33409796\n",
      " 2.6924011  2.90829969 3.76183459 3.31331065 0.72915158 1.31542556\n",
      " 2.48300582 2.57977901 3.2907873  3.69163492 2.12524328 3.69479733\n",
      " 1.25836626 3.58901649 2.42979068 3.25411755 1.82043994 3.4572596\n",
      " 2.43553782 3.30993984 3.83949541 2.5119199  2.57813198 3.69118337\n",
      " 2.33133938 2.54223969 2.57104168 2.40543843 3.76367901 3.80773554\n",
      " 3.84708675 1.74690751 3.77348939 2.04302181 2.94733725 2.61292769\n",
      " 1.39888616 3.15674301 1.97955832 2.23448443 3.1695339  3.7552121\n",
      " 3.74504135 2.73978198 2.49338722 1.97946755 2.24272826 3.71618995\n",
      " 2.49251826 3.16902523 3.315065   2.8838911  3.7294998  2.8094562\n",
      " 3.30032207 3.75081092 2.4729843  2.46908597 3.26466023 1.20219707\n",
      " 2.83688406 3.78149904 2.31767414 2.25683903 2.4347127  2.07245175\n",
      " 3.20241775 3.19509314 2.4995317  2.09960847 3.69246701 3.67968277\n",
      " 2.27997691 2.90854889 2.52612592 2.47900029 2.9294512  3.79008484\n",
      " 3.79468132 3.74888606 3.27137201 3.64085779 3.71280644 3.87551078\n",
      " 2.41611215 2.2646813  3.84626003 2.94495125 1.36128514 2.9613331\n",
      " 3.26412497 2.28121688 3.32198004 2.53809018 2.11272855 3.29562266\n",
      " 3.71896468 2.32027574 3.76720952 2.58472238 3.34600816 2.54953216\n",
      " 2.91354058 3.4050516  2.85683453 3.36199289 2.24241205 2.83289852\n",
      " 3.19614221 3.65568811 3.28326164 3.70567218 1.57344109 1.49873706\n",
      " 2.24953792 3.70203413 3.7586503  2.17333265 3.67565095 3.67760087\n",
      " 2.26129527 2.03061682 1.76170792 2.52768341 3.74789244 3.820347\n",
      " 3.79570959 3.33018169 3.77165887 3.85607082 2.59089329 2.93411164\n",
      " 3.7223468  2.70392266 2.97658284 1.25235326 3.27384678 2.37697422\n",
      " 3.88978416 3.78566692 3.44397809 1.99449962 3.75976778 2.00123923\n",
      " 2.28130386 3.24331941 2.32848135 3.81532446 3.90361917 2.90137331\n",
      " 2.09490745 3.73736228 3.27017895 3.48837701 3.65178141 2.29235124\n",
      " 3.29220623 2.18865438 3.70436281 3.85147836 2.64248593 1.55079602\n",
      " 2.18583981 2.45159203 2.88552056 3.74475311 3.86877383 2.31092913\n",
      " 1.83036267 3.33562764 2.62942479 3.38243877 3.26243973 3.32896177\n",
      " 2.13334179 1.54088289 3.65587501 3.27793287 2.97889917 2.41596821\n",
      " 3.65084744 3.67648509 2.64081918 3.32405643 1.57649215 2.55510796\n",
      " 2.93352873 2.88025598 1.9177873  2.62388361 3.29412938 2.8689251\n",
      " 1.51829356 3.66613623 2.54910658 1.83612971 3.32367769 3.90414799\n",
      " 3.30962625 3.83101618 3.21080598 3.33824425 3.33452536 2.16975162\n",
      " 3.75408397 2.66224556 3.69772739 1.6146112  2.60138591 2.51210232\n",
      " 1.52691714 2.85879014 1.98324727 3.72873032 1.49051032 1.83469444\n",
      " 2.96944352 3.35452662 2.84059045 2.24357118 3.31728715 2.45778467\n",
      " 2.25780118 1.48223094 3.71808399 2.88163972 3.74685584 2.02154032\n",
      " 1.28244109 2.9262025  2.9984149  3.2988276  2.26445532 3.32260223\n",
      " 2.91891904 3.63118466 3.82301713 3.8217843  2.75850843 1.44524246\n",
      " 3.66579187 2.00811048 2.49098965 3.25079823 3.93825351 3.68452468\n",
      " 3.67425999 2.61655352 3.69612848 3.84751398 3.66619756 3.66289086\n",
      " 1.72463741 3.7549477  2.43627985 2.49738557 2.0434743  1.94438321\n",
      " 3.66269644 2.58220101 1.96980473 2.69229493 3.65864942 3.75576994\n",
      " 2.54807343 4.0273716  2.28353772 2.93485505 2.25298582 1.7376515\n",
      " 3.66495748 2.74502906 2.16319708 2.06837385 2.22547209 1.9630282\n",
      " 1.96753715 2.29531688 1.82240542 2.57311633 2.52538054 3.38822499\n",
      " 1.5618869  3.64238786 3.83258904 3.00061922 3.44320416 1.82336135\n",
      " 3.77403556 2.59559683 3.77652299 2.5975192  2.59308454 2.87470077\n",
      " 3.84200979 2.27237324 3.31042196 2.48999045 3.73262326 2.25085432\n",
      " 3.49887511 1.22317293 3.96163417 2.60676067 2.00409113 3.02727837\n",
      " 1.98600506 3.27042738 2.82523134 3.73651627 3.18239495 3.67036697\n",
      " 3.72395109 2.27948374 2.84466083 3.60583595 3.687507   3.75229122\n",
      " 1.83064842 3.73318886 3.68696386 3.27152357 3.14486482 2.63504168\n",
      " 3.26881647 3.7671372  3.38024784 3.79782119 3.22612355 3.25787933\n",
      " 3.87856147 2.91744539 2.24943452 3.76418277 3.00168313 3.6117899\n",
      " 3.02846051 3.2507623  3.0793945  3.83017285 1.82673564 2.48030176\n",
      " 3.94577811 3.79422128 2.78498419 3.18407662 3.3126732  3.39378389\n",
      " 3.80461863 3.60969959 3.79035042 3.80011251 3.51712102 2.5384802\n",
      " 2.60223148 3.19169992 3.75847002 2.01765844 3.83711213 3.73377321\n",
      " 2.63490419 3.92566784 3.72192453 2.48147331 3.76178022 3.29747511\n",
      " 3.37023991 3.85220424 3.89164641 3.67034554 3.80284008 2.56952654\n",
      " 3.78322354 2.60981706 2.87763046 3.34943573 2.94609199 3.86602064\n",
      " 3.59389583 3.95977247 3.71777567 2.60006093 3.78386463 3.80858919\n",
      " 3.71457623 3.80300058 2.58766391 3.91914692 3.62365885 3.61199859\n",
      " 3.67664943 3.19069046 3.74532606 2.47254371 3.82889629 3.2198866\n",
      " 3.79804838 3.71847747 3.66828613 3.55304208 3.68505406 2.51168037\n",
      " 3.91201296 3.89984332 3.30192573 3.86045851 2.30705661 3.3429759\n",
      " 3.79888793 3.91018437 2.37409534 2.84464255 3.69885024 3.72795437\n",
      " 1.32156211 3.53913495 3.17950075 3.57608578 2.80968665 2.55787254\n",
      " 3.40507888 2.59519913 3.27671033 3.67619872 2.63329061 1.87912904\n",
      " 2.49051297 3.74843709 2.91490973 1.91641446 2.37902916 2.34940299\n",
      " 2.34750526 2.2200984  2.25906796 3.55971089 3.41150188 2.95302707\n",
      " 3.73882897 3.92313274 2.48046575 3.76346813 3.41054995 3.33014225\n",
      " 3.77229699 3.65035827 3.71052369 3.28214783 2.04665748 2.87822558\n",
      " 3.79766541 3.9376163  2.62194996 3.69835215 2.71534554 2.64578385\n",
      " 3.2839037  3.73509348 3.1699033  1.93804512 3.87404055 3.3815199\n",
      " 3.71860717 2.53279823 2.93785155 3.69851057 2.60505485 2.61628139\n",
      " 2.57964701 2.34806476 2.61165057 2.73020726 2.63626483 3.81604184\n",
      " 3.8921405  3.37103907 3.29064463 3.79432535 2.57706081 1.91975939\n",
      " 2.9730777  3.88871395 1.9420222  2.69138691 3.80035458 3.37326975\n",
      " 3.65490142 3.73393078 2.06031635 3.37665709 2.292057   2.58331852\n",
      " 2.15013142 4.00518131 3.87488353 2.56676613 3.31185667 3.99340469\n",
      " 3.4352724  2.47383296 3.02414085 2.96334259 3.79124178 2.28892068\n",
      " 3.70479893 3.41010906 3.83410546 3.77052975 3.69174257 3.83068504\n",
      " 4.06202715 3.82251172 3.37684166 3.82121266 2.97209674 3.8712479\n",
      " 2.55974804 2.0635048  3.76592083 2.90148931 3.29229362 3.76661598\n",
      " 2.27741251 3.91010311 2.63629211 4.06478862 2.94220555 3.96582601\n",
      " 3.93128319 3.76420457 2.63355264 4.02274512 4.01256374 3.37346991\n",
      " 4.10500363 3.71787245 3.08642106 3.88218435 3.97484    3.83030747\n",
      " 3.8060079  3.61627575 3.61983167 1.96629484 1.98808416 2.16289291\n",
      " 3.02823311 3.84162879 3.0716761  4.00537362 1.93935049 1.50657309\n",
      " 2.74073127 2.56112837 3.50688456 3.86096388 2.01641373 3.99898436\n",
      " 3.8769871  3.32380843 1.71686832 2.8352472  3.67726303 3.56841996\n",
      " 3.49419313 2.88007676 3.19168047]\n"
     ]
    }
   ],
   "source": [
    "player_skills = samples['skill'].mean(0)\n",
    "print(player_skills)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding the name of the player with the highest skill according to our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the highest skill level is:  4.230775324829369  and his name is:  Sen\n",
      "the lowest skill level is:  0.19198067695712345  and his name is:  INnoVation\n"
     ]
    }
   ],
   "source": [
    "ind = np.unravel_index(np.argmax(player_skills, axis=None), player_skills.shape)\n",
    "ind2 = np.unravel_index(np.argmin(player_skills, axis=None), player_skills.shape)\n",
    "\n",
    "print(\"the highest skill level is: \", player_skills[ind[0]], \" and his name is: \", playername[ind[0]])\n",
    "print(\"the lowest skill level is: \", player_skills[ind2[0]], \" and his name is: \", playername[ind2[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above result is surprising because Zest is a good player. According to this link https://www.lineups.com/esports/top-10-starcraft-ii-players-of-all-time/ these are the top ten players of all time. So they should have high skill levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mvp 's skill level is:  0.41083508825870557\n",
      "Life 's skill level is:  1.0979254677077046\n",
      "TaeJa 's skill level is:  0.3958064677725714\n",
      "MC 's skill level is:  0.5033267762289416\n",
      "Polt 's skill level is:  0.2542150593402713\n",
      "INnoVation 's skill level is:  0.19198067695712345\n",
      "Zest 's skill level is:  0.47922447073044566\n",
      "NesTea 's skill level is:  1.101697638422049\n",
      "MMA 's skill level is:  0.2246876148035381\n",
      "Rain 's skill level is:  0.8526257663685175\n"
     ]
    }
   ],
   "source": [
    "top10 = np.array([\n",
    "    playerid[\"Mvp\"],\n",
    "    playerid[\"Life\"],\n",
    "    playerid[\"TaeJa\"],\n",
    "    playerid[\"MC\"],\n",
    "    playerid[\"Polt\"],\n",
    "    playerid[\"INnoVation\"],\n",
    "    playerid[\"Zest\"],\n",
    "    playerid[\"NesTea\"],\n",
    "    playerid[\"MMA\"],\n",
    "    playerid[\"Rain\"]\n",
    "])\n",
    "\n",
    "for id in top10:\n",
    "    print(playername[id], \"'s skill level is: \", player_skills[id])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we're actually getting the opposite of what we were expecting. I think this has to do with the fact that I changed the sampling distribution from bernoulli_logit to binomial_logit. But we can just say that lower is better and still call this a good model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to predict which player will win, we might use a direct estimator of that quantity based on the sample values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sen has a  59.90946367675115 % chance of winning against  INnoVation\n"
     ]
    }
   ],
   "source": [
    "# Player 0 vs Player 1 prediction:\n",
    "def logit(z): return 1./(1.+np.exp(-z))\n",
    "\n",
    "# Use our model's win probability function (logistic of scaled difference)\n",
    "#  using the predicted skill difference for each sample:\n",
    "prob = logit( skill_data['scale']*(samples['skill'][:,ind[0]]-samples['skill'][:,ind2[0]]) ).mean()\n",
    "\n",
    "print(playername[ind[0]], \"has a \", prob * 100, \"% chance of winning against \", playername[ind2[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on online rankings, innovation should be the winner, not Sen, thus inversing them is a must."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### inversing the skill_levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_skills2 = np.array([abs(5-x) for x in player_skills])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the highest skill level is:  4.808019323042877  and his name is:  INnoVation\n",
      "the lowest skill level is:  0.7692246751706309  and his name is:  Sen\n"
     ]
    }
   ],
   "source": [
    "ind = np.unravel_index(np.argmax(player_skills2, axis=None), player_skills2.shape)\n",
    "ind2 = np.unravel_index(np.argmin(player_skills2, axis=None), player_skills2.shape)\n",
    "\n",
    "print(\"the highest skill level is: \", player_skills2[ind[0]], \" and his name is: \", playername[ind[0]])\n",
    "print(\"the lowest skill level is: \", player_skills2[ind2[0]], \" and his name is: \", playername[ind2[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mvp 's skill level is:  4.589164911741294\n",
      "Life 's skill level is:  3.9020745322922954\n",
      "TaeJa 's skill level is:  4.604193532227429\n",
      "MC 's skill level is:  4.496673223771058\n",
      "Polt 's skill level is:  4.745784940659728\n",
      "INnoVation 's skill level is:  4.808019323042877\n",
      "Zest 's skill level is:  4.520775529269554\n",
      "NesTea 's skill level is:  3.898302361577951\n",
      "MMA 's skill level is:  4.775312385196462\n",
      "Rain 's skill level is:  4.147374233631482\n"
     ]
    }
   ],
   "source": [
    "top10 = np.array([\n",
    "    playerid[\"Mvp\"],\n",
    "    playerid[\"Life\"],\n",
    "    playerid[\"TaeJa\"],\n",
    "    playerid[\"MC\"],\n",
    "    playerid[\"Polt\"],\n",
    "    playerid[\"INnoVation\"],\n",
    "    playerid[\"Zest\"],\n",
    "    playerid[\"NesTea\"],\n",
    "    playerid[\"MMA\"],\n",
    "    playerid[\"Rain\"]\n",
    "])\n",
    "\n",
    "for id in top10:\n",
    "    print(playername[id], \"'s skill level is: \", player_skills2[id])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INnoVation has a  59.90946367675114 % chance of winning against  Sen\n"
     ]
    }
   ],
   "source": [
    "# Highest skilled player vs Lowest skilled player:\n",
    "def logit(z): return 1./(1.+np.exp(-z))\n",
    "\n",
    "# Use our model's win probability function (logistic of scaled difference)\n",
    "#  using the predicted skill difference for each sample:\n",
    "prob = logit( skill_data['scale']*(samples['skill'][:,ind[0]]-samples['skill'][:,ind2[0]]) ).mean()\n",
    "\n",
    "print(playername[ind[0]], \"has a \", (1-prob) * 100, \"% chance of winning against \", playername[ind2[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks more correct. Not how, despite innovation having an incredibly high skill number, still has a relatively low chance of winning against Sen. This is due to how we scaled our data, the skill difference being scaled to only .1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Below we start using validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open(\"valid.csv\", newline='') as i:\n",
    "    reader = csv.reader(i)\n",
    "    valid_data= list(reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "304\n"
     ]
    }
   ],
   "source": [
    "print(ind2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "#0=date\n",
    "#1=p1name\n",
    "#2=p1win?\n",
    "#3=idk\n",
    "#4=p2name\n",
    "#5=p2win?\n",
    "number_correct_skill=0\n",
    "number_correct_prob=0\n",
    "winner=0\n",
    "for row in valid_data:\n",
    "#     ind = np.unravel_index(np.argmax(player_skills, axis=None), player_skills.shape)\n",
    "#     ind2 = np.unravel_index(np.argmin(player_skills, axis=None), player_skills.shape)\n",
    "\n",
    "    p1name=row[1]\n",
    "    p1win=row[2]\n",
    "    p2name=row[4]\n",
    "    prob = logit( skill_data['scale']*(samples['skill'][:,playerid[p1name]]-samples['skill'][:,playerid[p2name]])).mean()\n",
    "    \n",
    "    \n",
    "    #using prob. as the factor in correctness\n",
    "    if ((1-prob) * 100) > 50:\n",
    "        winner=1\n",
    "    else:\n",
    "        winner=2\n",
    "    #print(1-prob)\n",
    "    \n",
    "    #check to see if graphical model is correct\n",
    "    if p1win=='[winner]' and winner==1:\n",
    "        number_correct_prob+=1\n",
    "    elif p1win=='[loser]' and winner==2:\n",
    "        number_correct_prob+=1\n",
    "    \n",
    "    \n",
    "    #using calculated skill as the factor in correctness\n",
    "    if player_skills2[playerid[p1name]] > player_skills2[playerid[p2name]]:\n",
    "        winner=1\n",
    "    else:\n",
    "        winner=2\n",
    "    \n",
    "    if p1win=='[winner]' and winner==1:\n",
    "        number_correct_skill+=1\n",
    "    elif p1win=='[loser]' and winner==2:\n",
    "        number_correct_skill+=1      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For this graphical model, using only the calculate skill, it gets 60.17424234365526 % correct\n"
     ]
    }
   ],
   "source": [
    "prct_correct=(number_correct_skill/len(valid_data)) *100\n",
    "print(\"For this graphical model, using only the calculate skill, it gets\",prct_correct,\"% correct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For this graphical model, using only the calculated probability, it gets 60.17530609422702 % correct\n"
     ]
    }
   ],
   "source": [
    "prct_correct=(number_correct_prob/len(valid_data)) *100\n",
    "print(\"For this graphical model, using only the calculated probability, it gets\",prct_correct,\"% correct\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
